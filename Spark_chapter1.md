# Chapter 1: Introduction to Data Analysis with Spark
## What is Apache Spark?
It includes a unified stack composed of:
 - __Spark Core__: includes task scheduling, memory management, interactions with storage elements, fault recovery… Also contains the API for Resilient Distributed Datasets (RDD), main abstraction level of Spark.
 - __Spark SQL__: allows querying data via SQL and Apache Hive Query Language (HQL), from databases, JSON… Can be mixed with data manipulation in Python, Java and Scala.
 - __Spark Streaming__: enables processing live streams of data.
 - __MLib__: Machine Learning functionalities, like regression, classification, clustering, collaborative filtering, data import. Can be distributed in a cluster.
 - __GraphX__: manipulates graphs.
 - __Cluster Managers__:

